ğŸ“˜ Advanced Book Scraper CLI

A scalable, multi-threaded command-line web scraping tool built in Python.
Designed with production-oriented architecture, retry handling, encoding safety, and structured output.

ğŸ“Œ Project Overview

This project demonstrates a robust web scraping pipeline using Python.
It extracts structured book data from BooksToScrape and provides:

Parallel data extraction

Pagination automation

Clean numeric parsing

Structured logging

CLI-based filtering and sorting

CSV export with analytics summary

The goal of this project is to simulate real-world scraper design patterns rather than build a simple script.

âš™ï¸ Core Capabilities
ğŸ”„ Concurrent Scraping

Implements ThreadPoolExecutor to fetch multiple pages efficiently.

ğŸ” Retry Strategy

Uses urllib3 Retry with HTTPAdapter for resilient network handling.

ğŸ” Session Management

Leverages requests.Session() for connection pooling and improved performance.

ğŸ“„ Automatic Pagination Detection

Dynamically determines total available pages.

ğŸ§¹ Encoding-Safe Data Parsing

Handles UTF-8 encoding and currency symbol anomalies.

ğŸ§¾ CLI-Based Filtering & Sorting

Search books by keyword and sort results by price.

ğŸ“Š Analytics Summary

Automatically calculates:

Total Matches

Average Price

Cheapest Book

Most Expensive Book

ğŸ— Architecture Design
BookScraper Class
â”‚
â”œâ”€â”€ Session Initialization (Retry + Headers)
â”œâ”€â”€ Pagination Detection
â”œâ”€â”€ Page Scraping (Concurrent Execution)
â”œâ”€â”€ Data Parsing & Cleaning
â”œâ”€â”€ Filtering Logic
â”œâ”€â”€ Sorting Logic
â”œâ”€â”€ CSV Export
â””â”€â”€ Structured Output + Logging


This modular design improves:

Maintainability

Scalability

Testability

ğŸ›  Tech Stack
Component	Technology
Language	Python 3.x
HTTP Client	requests
Parsing	BeautifulSoup4
Concurrency	concurrent.futures
CLI Interface	argparse
Logging	logging
Retry Handling	urllib3 Retry
ğŸš€ Installation

Clone repository:

git clone https://github.com/Nagukore/advanced-book-scraper.git
cd advanced-book-scraper


Create virtual environment:

python -m venv .venv
.venv\Scripts\activate


Install dependencies:

pip install -r requirements.txt

â–¶ Usage Examples
Basic Keyword Search
python main.py --keyword travel

Sort by Price (Ascending)
python main.py --keyword travel --sort asc

Limit Pages
python main.py --keyword travel --pages 10

Custom Output File
python main.py --keyword travel --output travel_books.csv

ğŸ“Š Sample Output Structure

Console Output:

No   Title                                Price     Rating   Page
--------------------------------------------------------------------
1    It's Only the Himalayas              Â£45.17    Two      5
...


Summary:

Total Matches: 12
Average Price: Â£34.56
Cheapest: Â£12.95
Most Expensive: Â£57.83


CSV Output:

Title	Price	Rating	Page
ğŸ¯ Engineering Highlights

Designed using OOP principles

Implements concurrency for performance

Handles real-world encoding issues

Applies retry/backoff mechanism

Built as reusable CLI tool

Clean Git workflow & documentation

ğŸ“ˆ Potential Enhancements

SQLite integration

Category-wise scraping

REST API wrapper (FastAPI)

Streamlit analytics dashboard

Docker containerization

Automated unit tests

âš  Disclaimer

This scraper is built for educational purposes using a public sandbox website.

ğŸ‘¤ Author

Nagesh
AI/ML & Web Development Enthusiast
Focused on scalable system design and automation tools.