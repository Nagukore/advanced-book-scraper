# ğŸ“˜ Advanced Book Scraper CLI

> A scalable, multi-threaded command-line web scraping tool built in Python.  
> Designed using production-oriented architecture with retry handling, encoding safety, concurrency, and structured output.

---

## ğŸ“Œ Project Overview

This project demonstrates a robust scraping pipeline built with clean architecture principles.

It extracts structured book data from:

ğŸ”— http://books.toscrape.com

### ğŸ¯ Objectives

- Simulate real-world scraper architecture
- Implement concurrency for performance
- Handle encoding & currency parsing issues
- Build a reusable CLI-based scraping tool

---

## ğŸš€ Key Capabilities

| Capability | Description |
|------------|------------|
| ğŸ”„ Concurrent Scraping | Uses `ThreadPoolExecutor` for parallel page extraction |
| ğŸ” Retry Strategy | Implements `urllib3 Retry` with HTTPAdapter |
| ğŸ” Session Pooling | Uses `requests.Session()` for connection reuse |
| ğŸ“„ Pagination Detection | Automatically detects total page count |
| ğŸ§¹ Encoding-Safe Parsing | Handles UTF-8 and currency anomalies |
| ğŸ§¾ CLI Filtering | Keyword-based filtering using `argparse` |
| ğŸ“Š Analytics Summary | Calculates average, min, and max price |
| ğŸ“ CSV Export | Structured export to CSV |

---

## ğŸ— Architecture Overview

BookScraper Class
â”‚
â”œâ”€â”€ Session Initialization (Retry + Headers)
â”œâ”€â”€ Pagination Detection
â”œâ”€â”€ Page Scraping (Concurrent Execution)
â”œâ”€â”€ Data Parsing & Cleaning
â”œâ”€â”€ Filtering Logic
â”œâ”€â”€ Sorting Logic
â”œâ”€â”€ CSV Export
â””â”€â”€ Structured Output + Logging


### ğŸ“ˆ Design Benefits

- Maintainability  
- Scalability  
- Testability  
- Clean separation of concerns  

---

## ğŸ›  Technology Stack

| Layer | Technology |
|-------|------------|
| Language | Python 3.x |
| HTTP Client | requests |
| HTML Parsing | BeautifulSoup4 |
| Concurrency | concurrent.futures |
| CLI Interface | argparse |
| Logging | logging |
| Retry Handling | urllib3 Retry |

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Nagukore/advanced-book-scraper.git
cd advanced-book-scraper
2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
â–¶ Usage Examples
ğŸ” Basic Keyword Search
python main.py --keyword travel
ğŸ“Š Sort by Price (Ascending)
python main.py --keyword travel --sort asc
ğŸ“„ Limit Pages
python main.py --keyword travel --pages 10
ğŸ“ Custom Output File
python main.py --keyword travel --output travel_books.csv
ğŸ“Š Output Structure
Console Output
Field	Description
Title	Book Title
Price	Book Price
Rating	Star Rating
Page	Page Number
Summary Metrics
Total Matches: 12
Average Price: Â£34.56
Cheapest: Â£12.95
Most Expensive: Â£57.83
CSV Output Columns
Title	Price	Rating	Page
ğŸ¯ Engineering Highlights
Object-Oriented Design (OOP)

Concurrent execution for performance

Retry & backoff strategy

Encoding-safe numeric parsing

Modular CLI tool design

Production-style logging

ğŸ“ˆ Future Improvements
SQLite database integration

Category-based scraping

REST API wrapper (FastAPI)

Streamlit analytics dashboard

Docker containerization

Unit testing suite

âš  Disclaimer
This scraper is built for educational purposes using a publicly available sandbox website.

ğŸ‘¤ Author
Nagesh
AI/ML & Web Development Enthusiast
Focused on scalable system design and automation tools.